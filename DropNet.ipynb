{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check tensorflow version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check state of GPUs\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "<b>Dependencies required:</b>\n",
    "- tensorflow2.x\n",
    "- keras (comes from tensorflow.keras)\n",
    "- numpy\n",
    "- copy\n",
    "- sklearn\n",
    "- matplotlib\n",
    "\n",
    "<b>Setup requirements:</b>\n",
    "- Set up a folder named 'Images' (same directory as this Jupyter Notebook) to store the output images from the model\n",
    "- Set up a folder named 'Caches' (same directory as this Jupyter Notebook) to store the caches from the model\n",
    "\n",
    "<b>Section descriptions:</b>\n",
    "- <b>Section 1: Generic Initialization</b>\n",
    "    - Run all the code under Section 1. These are the code to define the main functions required for the experiments\n",
    "- <b>Section 2: Load Cache to Print Graph (if required)</b>\n",
    "    - Run the codes here only if you need to print graphs from a cahce in the Caches folder\n",
    "- <b>Section 3: MNIST</b>\n",
    "    - Run the codes here for experiments on the MNIST dataset.\n",
    "        - Section 3.1: Customize Model\n",
    "            - Allows you to customize the model used for the experiment.\n",
    "        - Section 3.2: Evaluate Model\n",
    "            - Allows you to run code to evaluate performance of various metrics.\n",
    "        - Section 3.3: Oracle Comparison\n",
    "            - Allows you to run code to evaluate performance of min, max and min_layer metrics against the oracle\n",
    "        - Section 3.4: Random Initialization\n",
    "            - Allows you to run code to compare performance of random initialization on the final pruned model vs original initialization\n",
    "        - Section 3.5: Compare Percent\n",
    "            - Allows you to run code to compare effect on accuracy based on proportion of nodes/filters dropped per training cycle\n",
    "- <b>Section 4: CIFAR10</b>\n",
    "    - Run the codes here for experiments on the CIFAR10 dataset\n",
    "        - Section 4.1: Customize Model\n",
    "            - Allows you to customize the model used for the experiment.\n",
    "        - Section 4.2: Evaluate Model\n",
    "            - Allows you to run code to evaluate performance of various metrics.\n",
    "        - Section 4.3: Oracle Comparison\n",
    "            - Allows you to run code to evaluate performance of min, max and min_layer metrics against the oracle\n",
    "        - Section 4.4: Random Initialization\n",
    "            - Allows you to run code to compare performance of random initialization on the final pruned model vs original initialization\n",
    "        - Section 4.5: Compare Percent\n",
    "            - Allows you to run code to compare effect on accuracy based on proportion of nodes/filters dropped per training cycle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Generic Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenmask(mask):\n",
    "    \"\"\"Returns the nodes of mask flattened\n",
    "    Input:\n",
    "    mask - the mask position, in dictionary form\n",
    "    Output:\n",
    "    maskflatten - the mask position, flattened out in 1D array\n",
    "    \"\"\"\n",
    "    maskflatten = []\n",
    "    for k, v in mask.items():\n",
    "        curmask = v.flatten()\n",
    "        maskflatten = np.hstack([maskflatten, curmask])\n",
    "    return maskflatten\n",
    "\n",
    "def getmask(layers, mask, maskflatten, mask_type = 'min', percentile = 0.2, printactivation = False, dropOne = False):\n",
    "    \"\"\" Updates mask after each training cycle\n",
    "    Inputs:\n",
    "    layers - Predicted node value per layer\n",
    "    mask - current mask\n",
    "    mask_type - type of mask: min, max, random, min_layer, max_layer, random_layer\n",
    "    maskflatten - Flattened masked indices per layer (1 for mask, 0 for no mask)\n",
    "    percentile - percentage of nodes remaining to be masked\n",
    "    printactivation - Boolean. Whether to print the activations per layer\n",
    "    dropOne - Boolean. Whether to drop only one node/filter at a time\n",
    "    \n",
    "    Output:\n",
    "    mask - final masks after masking percentile proportion of remaining nodes\n",
    "    \"\"\"\n",
    "    nodevalues = []\n",
    "    layermeans = {}\n",
    "    \n",
    "    # if only drop one, then percentile is 0\n",
    "    if dropOne:\n",
    "        percentile = 0\n",
    "    \n",
    "    # if only one layer\n",
    "    if(len(mask)==1):\n",
    "        layermeans[0] = np.mean(np.abs(layers), axis = 0).ravel()\n",
    "        nodevalues = np.hstack([nodevalues, layermeans[0]])\n",
    "        if printactivation:\n",
    "            print('Layer activations:', layermeans[0])\n",
    "        \n",
    "    # if more than one layer\n",
    "    else:\n",
    "        for i in range(len(mask)):\n",
    "            layermeans[i] = np.mean(np.abs(layers[i]), axis = 0).ravel()\n",
    "            nodevalues = np.hstack([nodevalues, layermeans[i]])\n",
    "            if printactivation:\n",
    "                print('Layer activations:', layermeans[i])\n",
    "\n",
    "    # remove only those in maskindex\n",
    "    maskflatten = np.ravel(np.where(maskflatten == 1))\n",
    "    \n",
    "    # find out the threshold node/filter value to remove\n",
    "    if len(maskflatten) > 0:\n",
    "        # for max mask\n",
    "        if mask_type == 'max':\n",
    "            sortedvalues = -np.sort(-nodevalues[maskflatten])\n",
    "            index = int((percentile)*len(sortedvalues))\n",
    "            maxindex = sortedvalues[index]\n",
    "            \n",
    "        # for min or % mask\n",
    "        else:\n",
    "            sortedvalues = np.sort(nodevalues[maskflatten])\n",
    "            index = int(percentile*len(sortedvalues))\n",
    "            maxindex = sortedvalues[index]\n",
    "                           \n",
    "    # Calculate the number of nodes to remove\n",
    "    nummask = 0\n",
    "    \n",
    "    for v in mask.values():\n",
    "        nummask += np.sum(v)\n",
    "    \n",
    "    totalnodes = int((percentile)*nummask)\n",
    "    \n",
    "    if dropOne:\n",
    "        totalnodes = 1\n",
    "\n",
    "    # remove at least one node\n",
    "    if (totalnodes == 0):\n",
    "        totalnodes = 1\n",
    "    \n",
    "    # identify the indices to drop for random mask\n",
    "    if mask_type == 'random':\n",
    "        indices = np.random.permutation(maskflatten)\n",
    "        # take only the first totalnodes number of nodes\n",
    "        indices = indices[:totalnodes]\n",
    "        \n",
    "        dropmaskindex = {}\n",
    "        startindex = 0\n",
    "        # assign nodes/filters to drop for each layer in dropmaskindex\n",
    "        for k, v in mask.items():\n",
    "            nummask += np.sum(v)\n",
    "            dropmaskindex[k] = indices[(indices>=startindex) & (indices < startindex + len(v))] - startindex\n",
    "            startindex += len(v)\n",
    "        \n",
    "    for i, layermean in layermeans.items():\n",
    "\n",
    "        #only if there is something to drop in current mask\n",
    "        if(np.sum(mask[i])>0):\n",
    "            # Have different indices for different masks\n",
    "            if mask_type == 'max':\n",
    "                indices = np.ravel(np.where(layermean>=maxindex))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "                indices = [j for j in indices if j in curindices]\n",
    "            # global random mask or layer random mask\n",
    "            elif mask_type == 'random_layer':\n",
    "                indices = np.ravel(np.where(mask[i].ravel()))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "            elif mask_type == 'random':\n",
    "                indices = dropmaskindex[i]\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "            # layer-wise max mask\n",
    "            elif mask_type == 'max_layer':\n",
    "                sortedvalues = -np.sort(-layermean[mask[i]==1])\n",
    "                index = int((percentile)*len(sortedvalues))\n",
    "                maxindex = sortedvalues[index]\n",
    "                indices = np.ravel(np.where(layermean>=maxindex))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "                indices = [j for j in indices if j in curindices]\n",
    "            # layer-wise min mask\n",
    "            elif mask_type == 'min_layer':\n",
    "                sortedvalues = np.sort(layermean[mask[i]==1])\n",
    "                index = int((percentile)*len(sortedvalues))\n",
    "                maxindex = sortedvalues[index]\n",
    "                indices = np.ravel(np.where(layermean<=maxindex))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "                indices = [j for j in indices if j in curindices]\n",
    "            # if this is min mask or % based mask\n",
    "            else:\n",
    "                indices = np.ravel(np.where(layermean<=maxindex))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "                indices = [j for j in indices if j in curindices]\n",
    "                \n",
    "        else:\n",
    "            #default\n",
    "            indices = np.ravel(np.where(mask[i]==1))\n",
    "\n",
    "        # shuffle the indices only if we are not dropping one node/filter\n",
    "        if (dropOne == False):\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        newmask = mask[i].ravel()\n",
    "\n",
    "        # for layer masks, total nodes dropped is by percentile of the layer of each mask\n",
    "        if(mask_type == 'random_layer') or mask_type == 'min_layer' or mask_type == 'max_layer':\n",
    "            initialpercent = np.sum(mask[i])*1.0/len(mask[i].ravel())\n",
    "            totalnodes = int(initialpercent*(percentile)*len(mask[i].ravel()))\n",
    "\n",
    "            # remove at least 1 node\n",
    "            if (totalnodes == 0):\n",
    "                totalnodes = 1\n",
    "\n",
    "        if(len(indices)>0):\n",
    "\n",
    "            # remove at most totalnodes number of nodes\n",
    "            if(len(indices)>totalnodes):\n",
    "                indices = indices[:totalnodes]\n",
    "\n",
    "            # remove nodes\n",
    "            newmask[indices] = 0\n",
    "\n",
    "            # updated totalnodes to be removed\n",
    "            totalnodes = totalnodes - len(indices)\n",
    "\n",
    "        # reshape to fit new mask\n",
    "        mask[i] = newmask.reshape(mask[i].shape)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def resetmask(mask):\n",
    "    \"\"\"Resets mask to initial start state of all ones\"\"\"\n",
    "    for k, v in mask.items():\n",
    "        mask[k] = np.ones_like(v)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def comparemask(mask1, mask2):\n",
    "    \"\"\" Compares how similar both masks (mask1, mask2) are and returns a percentage similarity \"\"\"\n",
    "    count = 0\n",
    "    totalcount = 0\n",
    "    for k, v in mask1.items():\n",
    "        count += np.sum(mask1[k] == mask2[k])\n",
    "        totalcount += len(mask1[k].ravel())\n",
    "        \n",
    "    return count/totalcount\n",
    "\n",
    "def percentmask(mask):\n",
    "    \"\"\"Returns the percentage of mask that contains 1s\"\"\"\n",
    "    nummask = 0\n",
    "    totalmask = 0\n",
    "    \n",
    "    for v in mask.values():\n",
    "        nummask += np.sum(v)\n",
    "        totalmask += len(v.ravel())\n",
    "        \n",
    "    return nummask/totalmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def comparerandom(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "                                    callbacks = [EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5)], \n",
    "                 metrics = ['accuracy'], num_epochs = 100, percentile = 0.2, verbose = 0, numtrials = 15, printvalue = True, printmask = False, printactivation = False):\n",
    "    \"\"\" Function to compare metrics with randominit \n",
    "    Inputs:\n",
    "    opt - Keras optimizer\n",
    "    loss - Keras loss\n",
    "    callbacks - Keras callbacks\n",
    "    metrics - Keras metrics\n",
    "    num_epochs - Number of epochs for each training cycle\n",
    "    percentile - Percentile to drop the nodes\n",
    "    verbose - Keras verbose option\n",
    "    numtrials - Number of different experiments to run, each with different random seed\n",
    "    printvalue  - Boolean. Whether to print the accuracies and losses for each pruning percentage\n",
    "    printmask - Boolean. Whether to print the mask values\n",
    "    printactivation - Boolean. Whether to print the node/filter's activation values\n",
    "    \n",
    "    Output:\n",
    "    caches - Cache containing accuracies, losses, early stopping iteration and oracle comparison\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables\n",
    "    percentremoved ={}\n",
    "    train_accuracies = {}\n",
    "    valid_accuracies = {}\n",
    "    test_accuracies = {}\n",
    "    train_losses = {}\n",
    "    valid_losses ={}\n",
    "    test_losses = {}\n",
    "    early_stopping = {}\n",
    "    oraclecomparison = {}\n",
    "    masktypes = ['min', 'randominit']\n",
    "    \n",
    "    for masktype in masktypes:\n",
    "        percentremoved[masktype] = []\n",
    "        train_accuracies[masktype] = []\n",
    "        valid_accuracies[masktype] = []\n",
    "        test_accuracies[masktype] = []\n",
    "        train_losses[masktype] = []\n",
    "        valid_losses[masktype] = []\n",
    "        test_losses[masktype] = []\n",
    "        early_stopping[masktype] = []\n",
    "        \n",
    "    # do for numtrials number of random seeds\n",
    "    for random_seed in range(numtrials):\n",
    "        print('>>>     Random seed number:', random_seed)\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        tf.random.set_seed(random_seed)   \n",
    "        \n",
    "        # Initialize the model\n",
    "        mask, model, activationmodel = initializemodel()\n",
    "        # model.summary()\n",
    "        model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "        \n",
    "        # save original weights\n",
    "        weights_initial = model.get_weights()\n",
    "\n",
    "        mask=resetmask(mask)\n",
    "        percent = percentmask(mask)\n",
    "\n",
    "        while percent > 0.1:\n",
    "            print('\\n>>> Currently doing min mask <<<')\n",
    "            tf.keras.backend.clear_session()\n",
    "            np.random.seed(random_seed)\n",
    "            tf.random.set_seed(random_seed)  \n",
    "            \n",
    "            # Initialize the model with the new mask\n",
    "            _, model, activationmodel = initializemodel(mask)\n",
    "\n",
    "            #Initialize to original weights\n",
    "            model.set_weights(weights_initial)\n",
    "            model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "\n",
    "            history = model.fit(x_train, y_train, epochs = num_epochs, validation_data = (x_val, y_val), shuffle = False, callbacks = callbacks, verbose = verbose)\n",
    "            results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "            percent = percentmask(mask)\n",
    "            train_accuracy = history.history['accuracy'][-1]\n",
    "            valid_accuracy = history.history['val_accuracy'][-1]\n",
    "            test_accuracy = results[1]\n",
    "            train_loss = history.history['loss'][-1]\n",
    "            valid_loss = history.history['val_loss'][-1]\n",
    "            test_loss = results[0]\n",
    "            early = len(history.history['accuracy'])\n",
    "\n",
    "            # Append the values for accuracy and loss\n",
    "            percentremoved['min'].append(percent)\n",
    "            train_accuracies['min'].append(train_accuracy)\n",
    "            valid_accuracies['min'].append(valid_accuracy)\n",
    "            test_accuracies['min'].append(test_accuracy)\n",
    "            train_losses['min'].append(train_loss)\n",
    "            valid_losses['min'].append(valid_loss)\n",
    "            test_losses['min'].append(test_loss)\n",
    "            early_stopping['min'].append(early)\n",
    "\n",
    "            if printvalue:\n",
    "                print('Percentage remaining', percent, end = ' ')\n",
    "                print('Layer nodes:', [np.sum(mask[i]) for i in mask.keys()], end = ' ')\n",
    "                if printmask:\n",
    "                    print('Mask:', mask)\n",
    "                print('Train Acc:', train_accuracy, end = ' ')\n",
    "                print('Val Acc:', valid_accuracy, end = ' ')\n",
    "                print('Test Acc:', test_accuracy)\n",
    "                print('Train Loss:', train_loss, end = ' ')\n",
    "                print('Val loss:', valid_loss, end = ' ')\n",
    "                print('Test Loss:', test_loss)\n",
    "                print('Early stopping iteration:', early)\n",
    "                \n",
    "            # Remove nodes for next iteration based on metric\n",
    "            layers = activationmodel.predict(x_train)\n",
    "            maskflatten = flattenmask(mask)\n",
    "\n",
    "            # random init mask\n",
    "            print('\\n>>> Currently doing randominit mask <<<')\n",
    "            # Initialize the model with the new mask with random seed\n",
    "            tf.keras.backend.clear_session()\n",
    "            np.random.seed(random_seed+20)\n",
    "            tf.random.set_seed(random_seed+20)    \n",
    "            _, model, activationmodel = initializemodel(mask)\n",
    "\n",
    "            model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "\n",
    "            history = model.fit(x_train, y_train, epochs = num_epochs, validation_data = (x_val, y_val), shuffle = False, callbacks = callbacks, verbose = verbose)\n",
    "            results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "            percent = percentmask(mask)\n",
    "            train_accuracy = history.history['accuracy'][-1]\n",
    "            valid_accuracy = history.history['val_accuracy'][-1]\n",
    "            test_accuracy = results[1]\n",
    "            train_loss = history.history['loss'][-1]\n",
    "            valid_loss = history.history['val_loss'][-1]\n",
    "            test_loss = results[0]\n",
    "            early = len(history.history['accuracy'])\n",
    "\n",
    "            # Append the values for accuracy and loss\n",
    "            percentremoved['randominit'].append(percent)\n",
    "            train_accuracies['randominit'].append(train_accuracy)\n",
    "            valid_accuracies['randominit'].append(valid_accuracy)\n",
    "            test_accuracies['randominit'].append(test_accuracy)\n",
    "            train_losses['randominit'].append(train_loss)\n",
    "            valid_losses['randominit'].append(valid_loss)\n",
    "            test_losses['randominit'].append(test_loss)\n",
    "            early_stopping['randominit'].append(early)\n",
    "\n",
    "            if printvalue:\n",
    "                print('Percentage remaining', percent, end = ' ')\n",
    "                print('Layer nodes:', [np.sum(mask[i]) for i in mask.keys()], end = ' ')\n",
    "                if printmask:\n",
    "                    print('Mask:', mask)\n",
    "                print('Train Acc:', train_accuracy, end = ' ')\n",
    "                print('Val Acc:', valid_accuracy, end = ' ')\n",
    "                print('Test Acc:', test_accuracy)\n",
    "                print('Train Loss:', train_loss, end = ' ')\n",
    "                print('Val loss:', valid_loss, end = ' ')\n",
    "                print('Test Loss:', test_loss)\n",
    "                print('Early stopping iteration:', early)\n",
    "                \n",
    "            # get new mask\n",
    "            mask = getmask(layers, mask, maskflatten, mask_type = 'min', percentile = percentile)\n",
    "            \n",
    "        cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "        printgraph(cache, 'randominit'+str(random_seed), numtrials = random_seed+1)\n",
    "\n",
    "    cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def generatemodel(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'],\n",
    "                  callbacks = [EarlyStopping(monitor='val_loss', mode = 'min', verbose=0, patience=5)], \n",
    "                    num_epochs = 100, percentile = 0.2, verbose = 0, numtrials = 15, printvalue = True, printmask = False, printactivation = False):\n",
    "    \"\"\" Function to evaluate the model against various metrics\n",
    "    Inputs:\n",
    "    opt - Keras optimizer\n",
    "    loss - Keras loss\n",
    "    metrics - Keras metrics\n",
    "    callbacks - Keras callbacks\n",
    "    num_epochs - Number of epochs for each training cycle\n",
    "    percentile - Percentile to drop the nodes\n",
    "    verbose - Keras verbose option\n",
    "    numtrials - Number of different experiments to run, each with different random seed\n",
    "    printvalue  - Boolean. Whether to print the accuracies and losses for each pruning percentage\n",
    "    printmask - Boolean. Whether to print the mask values\n",
    "    printactivation - Boolean. Whether to print the node/filter's activation values\n",
    "    \n",
    "    Output:\n",
    "    caches - Cache containing accuracies, losses, early stopping iteration and oracle comparison\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables\n",
    "    percentremoved ={}\n",
    "    train_accuracies = {}\n",
    "    valid_accuracies = {}\n",
    "    test_accuracies = {}\n",
    "    train_losses = {}\n",
    "    valid_losses ={}\n",
    "    test_losses = {}\n",
    "    early_stopping = {}\n",
    "    oraclecomparison = {}\n",
    "    masktypes = ['min', 'max', 'random', 'min_layer', 'max_layer', 'random_layer']\n",
    "    \n",
    "    for masktype in masktypes:\n",
    "        percentremoved[masktype] = []\n",
    "        train_accuracies[masktype] = []\n",
    "        valid_accuracies[masktype] = []\n",
    "        test_accuracies[masktype] = []\n",
    "        train_losses[masktype] = []\n",
    "        valid_losses[masktype] = []\n",
    "        test_losses[masktype] = []\n",
    "        early_stopping[masktype] = []\n",
    "        \n",
    "    # do for numtrials number of random seeds\n",
    "    for random_seed in range(numtrials):\n",
    "        print('>>>     Random seed number:', random_seed)\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        tf.random.set_seed(random_seed)    \n",
    "        \n",
    "        # Initialize the model\n",
    "        mask, model, activationmodel = initializemodel()\n",
    "        # model.summary()\n",
    "        model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "        # save original weights\n",
    "        weights_initial = model.get_weights()\n",
    "    \n",
    "    # do for all mask types\n",
    "        for masktype in masktypes:\n",
    "            print('\\n>>> Currently doing', masktype, 'mask <<<')\n",
    "        \n",
    "            mask=resetmask(mask)\n",
    "            percent = percentmask(mask)\n",
    "            \n",
    "            while percent > 0.1:\n",
    "                # Initialize the model with the new mask\n",
    "                tf.keras.backend.clear_session()\n",
    "                np.random.seed(random_seed)\n",
    "                tf.random.set_seed(random_seed)  \n",
    "                \n",
    "                _, model, activationmodel = initializemodel(mask)\n",
    "\n",
    "                #Initialize to original weights\n",
    "                model.set_weights(weights_initial)\n",
    "                model.compile(optimizer = opt, loss = loss, metrics = metrics)  \n",
    "\n",
    "                history = model.fit(x_train, y_train, epochs = num_epochs, validation_data = (x_val, y_val), callbacks = callbacks, shuffle = False, verbose = verbose)\n",
    "                results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "                percent = percentmask(mask)\n",
    "                train_accuracy = history.history['accuracy'][-1]\n",
    "                valid_accuracy = history.history['val_accuracy'][-1]\n",
    "                test_accuracy = results[1]\n",
    "                train_loss = history.history['loss'][-1]\n",
    "                valid_loss = history.history['val_loss'][-1]\n",
    "                test_loss = results[0]\n",
    "                early = len(history.history['accuracy'])\n",
    "\n",
    "                # Append the values for accuracy and loss\n",
    "                percentremoved[masktype].append(percent)\n",
    "                train_accuracies[masktype].append(train_accuracy)\n",
    "                valid_accuracies[masktype].append(valid_accuracy)\n",
    "                test_accuracies[masktype].append(test_accuracy)\n",
    "                train_losses[masktype].append(train_loss)\n",
    "                valid_losses[masktype].append(valid_loss)\n",
    "                test_losses[masktype].append(test_loss)\n",
    "                early_stopping[masktype].append(early)\n",
    "\n",
    "                if printvalue:\n",
    "                    print('Percentage remaining', percent, end = ' ')\n",
    "                    print('Layer nodes:', [np.sum(mask[i]) for i in mask.keys()], end = ' ')\n",
    "                    if printmask:\n",
    "                        print('Mask:', mask)\n",
    "                    print('Train Acc:', train_accuracy, end = ' ')\n",
    "                    print('Val Acc:', valid_accuracy, end = ' ')\n",
    "                    print('Test Acc:', test_accuracy)\n",
    "                    print('Train Loss:', train_loss, end = ' ')\n",
    "                    print('Val loss:', valid_loss, end = ' ')\n",
    "                    print('Test Loss:', test_loss)\n",
    "                    print('Early stopping iteration:', early)\n",
    "\n",
    "                # Remove nodes for next iteration based on metric\n",
    "                layers = activationmodel.predict(x_train)\n",
    "                maskflatten = flattenmask(mask)\n",
    "                mask = getmask(layers, mask, maskflatten, mask_type = masktype, percentile = percentile, printactivation = printactivation)\n",
    "                \n",
    "        cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "        printgraph(cache, 'evaluate'+str(random_seed), numtrials = random_seed+1)\n",
    "\n",
    "    cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def oraclemodel(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'],\n",
    "                  callbacks = [EarlyStopping(monitor='val_loss', mode = 'min', verbose=0, patience=5)], \n",
    "                    num_epochs = 100, percentile = 0.2, verbose = 0, numtrials = 15, printvalue = True, printmask = False, printactivation = False):\n",
    "    \"\"\" Function to evaluate the model against the oracle\n",
    "    Inputs:\n",
    "    opt - Keras optimizer\n",
    "    loss - Keras loss\n",
    "    metrics - Keras metrics\n",
    "    callbacks - Keras callbacks\n",
    "    num_epochs - Number of epochs for each training cycle\n",
    "    percentile - Percentile to drop the nodes\n",
    "    verbose - Keras verbose option\n",
    "    numtrials - Number of different experiments to run, each with different random seed\n",
    "    printvalue  - Boolean. Whether to print the accuracies and losses for each pruning percentage\n",
    "    printmask - Boolean. Whether to print the mask values\n",
    "    printactivation - Boolean. Whether to print the node/filter's activation values\n",
    "    \n",
    "    Output:\n",
    "    caches - Cache containing accuracies, losses, early stopping iteration and oracle comparison\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables\n",
    "    percentremoved ={}\n",
    "    train_accuracies = {}\n",
    "    valid_accuracies = {}\n",
    "    test_accuracies = {}\n",
    "    train_losses = {}\n",
    "    valid_losses ={}\n",
    "    test_losses = {}\n",
    "    early_stopping = {}\n",
    "    oraclecomparison = {}\n",
    "    oraclemasks = []\n",
    "    masktypes = ['oracle', 'min', 'max', 'random_layer']\n",
    "    \n",
    "    for masktype in masktypes:\n",
    "        percentremoved[masktype] = []\n",
    "        train_accuracies[masktype] = []\n",
    "        valid_accuracies[masktype] = []\n",
    "        test_accuracies[masktype] = []\n",
    "        train_losses[masktype] = []\n",
    "        valid_losses[masktype] = []\n",
    "        test_losses[masktype] = []\n",
    "        early_stopping[masktype] = []\n",
    "        oraclecomparison[masktype] = []\n",
    "        \n",
    "    # do for numtrials number of random seeds\n",
    "    for random_seed in range(numtrials):\n",
    "        print('>>>     Random seed number:', random_seed)\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        tf.random.set_seed(random_seed)    \n",
    "        \n",
    "        # Initialize the model\n",
    "        mask, model, activationmodel = initializemodel()\n",
    "        # model.summary()\n",
    "        model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "        # save original weights\n",
    "        weights_initial = model.get_weights()\n",
    "        \n",
    "        # reset oracle masks\n",
    "        oraclemasks = []\n",
    "                 \n",
    "        # do for all mask types\n",
    "        for masktype in masktypes:\n",
    "            print('\\n>>> Currently doing', masktype, 'mask <<<')\n",
    "        \n",
    "            mask=resetmask(mask)\n",
    "            percent = percentmask(mask)\n",
    "            iterationnum = 0\n",
    "            \n",
    "            while percent > 0.1:\n",
    "                # Initialize the model with the new mask\n",
    "                tf.keras.backend.clear_session()\n",
    "                np.random.seed(random_seed)\n",
    "                tf.random.set_seed(random_seed)  \n",
    "                \n",
    "                _, model, activationmodel = initializemodel(mask)\n",
    "                \n",
    "                #Initialize to original weights\n",
    "                model.set_weights(weights_initial)\n",
    "                model.compile(optimizer = opt, loss = loss, metrics = metrics)  \n",
    "\n",
    "                history = model.fit(x_train, y_train, epochs = num_epochs, validation_data = (x_val, y_val), callbacks = callbacks, shuffle = False, verbose = verbose)\n",
    "                results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "                \n",
    "                weights_after_training = model.get_weights()\n",
    "\n",
    "                percent = percentmask(mask)\n",
    "                train_accuracy = history.history['accuracy'][-1]\n",
    "                valid_accuracy = history.history['val_accuracy'][-1]\n",
    "                test_accuracy = results[1]\n",
    "                train_loss = history.history['loss'][-1]\n",
    "                valid_loss = history.history['val_loss'][-1]\n",
    "                test_loss = results[0]\n",
    "                early = len(history.history['accuracy'])\n",
    "\n",
    "                # Append the values for accuracy and loss\n",
    "                percentremoved[masktype].append(percent)\n",
    "                train_accuracies[masktype].append(train_accuracy)\n",
    "                valid_accuracies[masktype].append(valid_accuracy)\n",
    "                test_accuracies[masktype].append(test_accuracy)\n",
    "                train_losses[masktype].append(train_loss)\n",
    "                valid_losses[masktype].append(valid_loss)\n",
    "                test_losses[masktype].append(test_loss)\n",
    "                early_stopping[masktype].append(early)\n",
    "                \n",
    "                # Compare mask with oracle if this is iteration 1 and above (when there is a mask to compare)\n",
    "                if iterationnum == 0:\n",
    "                    compare = 1\n",
    "                else:\n",
    "                    compare = comparemask(mask, oraclemasks[iterationnum-1])\n",
    "                oraclecomparison[masktype].append(compare)\n",
    "\n",
    "                if printvalue:\n",
    "                    print('Percentage remaining', percent, end = ' ')\n",
    "                    print('Layer nodes:', [np.sum(mask[i]) for i in mask.keys()], end = ' ')\n",
    "                    if printmask:\n",
    "                        print('Mask:', mask)\n",
    "                    print('Train Acc:', train_accuracy, end = ' ')\n",
    "                    print('Val Acc:', valid_accuracy, end = ' ')\n",
    "                    print('Test Acc:', test_accuracy)\n",
    "                    print('Train Loss:', train_loss, end = ' ')\n",
    "                    print('Val loss:', valid_loss, end = ' ')\n",
    "                    print('Test Loss:', test_loss)\n",
    "                    print('Early stopping iteration:', early)\n",
    "                    print('Similaritiy with oracle:', compare)\n",
    "\n",
    "                # Remove nodes for next iteration for oracle by doing brute force comparison\n",
    "                if masktype == 'oracle':\n",
    "                    bestloss = 1000000\n",
    "                    bestmask = {}\n",
    "                    \n",
    "                    # Remove one existing node and compare accuracy\n",
    "                    for v in mask.values():\n",
    "                        for index in range(len(v)):\n",
    "                            # remove mask index only if it is non-zero\n",
    "                            if v[index] != 0:\n",
    "                                \n",
    "                                # take out mask index\n",
    "                                v[index] = 0\n",
    "                                \n",
    "                                # do the mask evaluation\n",
    "                                # Initialize the model with the new mask\n",
    "                                _, model, activationmodel = initializemodel(mask)\n",
    "\n",
    "                                #Initialize the weights to after training weights\n",
    "                                model.set_weights(weights_after_training)\n",
    "                                model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "                                # evaluate model using training data only\n",
    "                                results = model.evaluate(x_train, y_train, verbose = 0)\n",
    "                                \n",
    "                                # update accuracy and mask for best mask\n",
    "                                if(results[0] < bestloss):\n",
    "                                    bestloss = results[0]\n",
    "                                    bestmask = copy.deepcopy(mask)\n",
    "                                        \n",
    "                                # put back mask index\n",
    "                                v[index] = 1\n",
    "                        \n",
    "                    # store bestmask\n",
    "                    mask = copy.deepcopy(bestmask)\n",
    "                    oraclemasks.append(mask)\n",
    "                    \n",
    "                    if printvalue:\n",
    "                        print('Final mask selected:', mask)\n",
    "                    oraclecomparison[masktype].append(comparemask(mask, oraclemasks[iterationnum]))\n",
    "\n",
    "                else:\n",
    "                    # Remove nodes for next iteration based on metric\n",
    "                    layers = activationmodel.predict(x_train)\n",
    "                    maskflatten = flattenmask(mask)\n",
    "                    mask = getmask(layers, mask, maskflatten, mask_type = masktype, percentile = percentile, printactivation = printactivation, dropOne = True)\n",
    "                    oraclecomparison[masktype].append(comparemask(mask, oraclemasks[iterationnum]))\n",
    "                    \n",
    "                # Increment iteration number\n",
    "                iterationnum = iterationnum + 1\n",
    "                \n",
    "        cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "        printgraph(cache, 'oracle'+str(random_seed), numtrials = random_seed+1)\n",
    "\n",
    "    cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def comparepercentmask(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'],\n",
    "                  callbacks = [EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5)], \n",
    "                    num_epochs = 100, percentile = 0.2, verbose = 0, numtrials = 15, printvalue = True, printmask = False, printactivation = False):\n",
    "    \"\"\" Function to compare the effect of pruning proportions\n",
    "    Inputs:\n",
    "    opt - Keras optimizer\n",
    "    loss - Keras loss\n",
    "    metrics - Keras metrics\n",
    "    callbacks - Keras callbacks\n",
    "    num_epochs - Number of epochs for each training cycle\n",
    "    percentile - Percentile to drop the nodes\n",
    "    verbose - Keras verbose option\n",
    "    numtrials - Number of different experiments to run, each with different random seed\n",
    "    printvalue  - Boolean. Whether to print the accuracies and losses for each pruning percentage\n",
    "    printmask - Boolean. Whether to print the mask values\n",
    "    printactivation - Boolean. Whether to print the node/filter's activation values\n",
    "    \n",
    "    Output:\n",
    "    caches - Cache containing accuracies, losses, early stopping iteration and oracle comparison\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables\n",
    "    percentremoved ={}\n",
    "    train_accuracies = {}\n",
    "    valid_accuracies = {}\n",
    "    test_accuracies = {}\n",
    "    train_losses = {}\n",
    "    valid_losses ={}\n",
    "    test_losses = {}\n",
    "    early_stopping = {}\n",
    "    masktypes = ['0.2', '0.3', '0.4', '0.5', '0.9']\n",
    "    \n",
    "    for masktype in masktypes:\n",
    "        percentremoved[masktype] = []\n",
    "        train_accuracies[masktype] = []\n",
    "        valid_accuracies[masktype] = []\n",
    "        test_accuracies[masktype] = []\n",
    "        train_losses[masktype] = []\n",
    "        valid_losses[masktype] = []\n",
    "        test_losses[masktype] = []\n",
    "        early_stopping[masktype] = []\n",
    "        \n",
    "    # do for numtrials number of random seeds\n",
    "    for random_seed in range(numtrials):\n",
    "        print('>>>     Random seed number:', random_seed)\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        tf.random.set_seed(random_seed)    \n",
    "        \n",
    "        # Initialize the model\n",
    "        mask, model, activationmodel = initializemodel()\n",
    "        # model.summary()\n",
    "        model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "        # save original weights\n",
    "        weights_initial = model.get_weights()\n",
    "    \n",
    "    # do for all mask types\n",
    "        for masktype in masktypes:\n",
    "            print('\\n>>> Currently doing', masktype, 'mask <<<')\n",
    "        \n",
    "            mask=resetmask(mask)\n",
    "            percent = percentmask(mask)\n",
    "            \n",
    "            while percent > 0.1:\n",
    "                # Initialize the model with the new mask\n",
    "                tf.keras.backend.clear_session()\n",
    "                np.random.seed(random_seed)\n",
    "                tf.random.set_seed(random_seed)  \n",
    "                \n",
    "                _, model, activationmodel = initializemodel(mask)\n",
    "\n",
    "                #Initialize to original weights\n",
    "                model.set_weights(weights_initial)\n",
    "                model.compile(optimizer = opt, loss = loss, metrics = metrics)  \n",
    "\n",
    "                history = model.fit(x_train, y_train, epochs = num_epochs, validation_data = (x_val, y_val), callbacks = callbacks, shuffle = False, verbose = verbose)\n",
    "                results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "                percent = percentmask(mask)\n",
    "                train_accuracy = history.history['accuracy'][-1]\n",
    "                valid_accuracy = history.history['val_accuracy'][-1]\n",
    "                test_accuracy = results[1]\n",
    "                train_loss = history.history['loss'][-1]\n",
    "                valid_loss = history.history['val_loss'][-1]\n",
    "                test_loss = results[0]\n",
    "                early = len(history.history['accuracy'])\n",
    "\n",
    "                # Append the values for accuracy and loss\n",
    "                percentremoved[masktype].append(percent)\n",
    "                train_accuracies[masktype].append(train_accuracy)\n",
    "                valid_accuracies[masktype].append(valid_accuracy)\n",
    "                test_accuracies[masktype].append(test_accuracy)\n",
    "                train_losses[masktype].append(train_loss)\n",
    "                valid_losses[masktype].append(valid_loss)\n",
    "                test_losses[masktype].append(test_loss)\n",
    "                early_stopping[masktype].append(early)\n",
    "\n",
    "                if printvalue:\n",
    "                    print('Percentage remaining', percent, end = ' ')\n",
    "                    print('Layer nodes:', [np.sum(mask[i]) for i in mask.keys()], end = ' ')\n",
    "                    if printmask:\n",
    "                        print('Mask:', mask)\n",
    "                    print('Train Acc:', train_accuracy, end = ' ')\n",
    "                    print('Val Acc:', valid_accuracy, end = ' ')\n",
    "                    print('Test Acc:', test_accuracy)\n",
    "                    print('Train Loss:', train_loss, end = ' ')\n",
    "                    print('Val loss:', valid_loss, end = ' ')\n",
    "                    print('Test Loss:', test_loss)\n",
    "                    print('Early stopping iteration:', early)\n",
    "                    \n",
    "                # get the percentile from masktype\n",
    "                if masktype == '0.1': \n",
    "                    percentile = 0.1\n",
    "                elif masktype == '0.2': \n",
    "                    percentile = 0.2\n",
    "                elif masktype == '0.3': \n",
    "                    percentile = 0.3\n",
    "                elif masktype == '0.4': \n",
    "                    percentile = 0.4\n",
    "                elif masktype == '0.5': \n",
    "                    percentile = 0.5\n",
    "                elif masktype == '0.9': \n",
    "                    percentile = 0.9\n",
    "\n",
    "                # Remove nodes for next iteration based on metric\n",
    "                layers = activationmodel.predict(x_train)\n",
    "                maskflatten = flattenmask(mask)\n",
    "                mask = getmask(layers, mask, maskflatten, mask_type = 'min', percentile = percentile, printactivation = printactivation)\n",
    "\n",
    "        cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "        printgraph(cache, 'comparepercentmask'+str(random_seed), numtrials = random_seed+1)\n",
    "                \n",
    "    cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printgraph(cache, name, numtrials = 15, oracle = False):\n",
    "    \"\"\"Function to print graph\n",
    "    Input: \n",
    "    cache - Cache containing accuracies, losses, early stopping iteration and oracle comparison\n",
    "    name - name of model which is run\n",
    "    numtrials - number of experiments conducted\n",
    "    oracle - Boolean. Whether the oraclecomparison graph is required\n",
    "    \n",
    "    Outputs:\n",
    "    Graphs for training, validation, test accuracy, early stopping iteration, oracle comparison (optional)\"\"\"\n",
    "    \n",
    "    # unpack caches\n",
    "    percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison = cache\n",
    "    # sort masktypes by alphabetical order\n",
    "    masktypes = sorted(percentremoved.keys())\n",
    "\n",
    "    # Set colors\n",
    "    colors = {}\n",
    "    colors['min'] = 'b'\n",
    "    colors['max'] = 'r'\n",
    "    colors['random'] ='g'\n",
    "    colors['random_layer'] = 'y'\n",
    "    colors['min_layer'] = 'c'\n",
    "    colors['max_layer'] = 'm'\n",
    "    colors['randominit'] = 'y'\n",
    "    colors['oracle'] = 'm'\n",
    "    \n",
    "    # colors for percentage mask\n",
    "    colors['0.1'] = 'b'\n",
    "    colors['0.2'] = 'r'\n",
    "    colors['0.3'] = 'g'\n",
    "    colors['0.4'] = 'y'\n",
    "    colors['0.5'] = 'c'\n",
    "    colors['0.9'] = 'm'\n",
    "    \n",
    "    # format for various masks\n",
    "    fmt = {}\n",
    "    fmt['min'] = '-'\n",
    "    fmt['max'] = '-'\n",
    "    fmt['random'] ='--'\n",
    "    fmt['random_layer'] = '--'\n",
    "    fmt['min_layer'] = '-'\n",
    "    fmt['max_layer'] = '-'\n",
    "    fmt['randominit'] = '--'\n",
    "    fmt['minfast'] = '-'\n",
    "    fmt['oracle'] = '-'\n",
    "    \n",
    "    fmt['0.1'] = '-'\n",
    "    fmt['0.2'] = '-'\n",
    "    fmt['0.3'] = '-'\n",
    "    fmt['0.4'] = '-'\n",
    "    fmt['0.5'] = '-'\n",
    "    fmt['0.9'] = '-'\n",
    "    \n",
    "    import matplotlib.font_manager\n",
    "    from matplotlib import rc, rcParams\n",
    "    rc('font', family = 'STIXGeneral')\n",
    "    rc('xtick', labelsize=10) \n",
    "    rcParams.update({'figure.autolayout': True})\n",
    "    rcParams.update({'font.size': 14})\n",
    "    \n",
    "    # Plot figures for training accuracy\n",
    "    plt.figure()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xscale('log')\n",
    "    plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "    for masktype in masktypes:     \n",
    "        length = len(percentremoved[masktype])//numtrials\n",
    "        mean = []\n",
    "        std = []\n",
    "        for i in range(length):\n",
    "            mean.append(np.mean(train_accuracies[masktype][i::length]))\n",
    "            std.append(1.96*np.std(train_accuracies[masktype][i::length])/np.sqrt(numtrials))\n",
    "        plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)        \n",
    "    plt.ylabel('Training accuracy')\n",
    "    plt.xlabel('Proportion of nodes/filters remaining')\n",
    "    plt.legend(loc = 'lower left')\n",
    "    plt.savefig('Images/training_accuracy_{}.png'.format(name))\n",
    "\n",
    "    # Plot figures for validation accuracy\n",
    "    plt.figure()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xscale('log')\n",
    "    plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "    for masktype in masktypes:\n",
    "        length = len(percentremoved[masktype])//numtrials\n",
    "        mean = []\n",
    "        std = []\n",
    "        for i in range(length):\n",
    "            mean.append(np.mean(valid_accuracies[masktype][i::length]))\n",
    "            std.append(1.96*np.std(valid_accuracies[masktype][i::length])/np.sqrt(numtrials))\n",
    "        plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)\n",
    "    plt.ylabel('Validation accuracy')\n",
    "    plt.xlabel('Proportion of nodes/filters remaining')\n",
    "    plt.legend(loc = 'lower left')\n",
    "    plt.savefig('Images/validation_accuracy_{}.png'.format(name))\n",
    "\n",
    "    # Plot figures for test accuracy\n",
    "    plt.figure()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xscale('log')\n",
    "    plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "    for masktype in masktypes:\n",
    "        length = len(percentremoved[masktype])//numtrials\n",
    "        mean = []\n",
    "        std = []\n",
    "        for i in range(length):\n",
    "            mean.append(np.mean(test_accuracies[masktype][i::length]))\n",
    "            std.append(1.96*np.std(test_accuracies[masktype][i::length])/np.sqrt(numtrials))\n",
    "        plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)\n",
    "    plt.ylabel('Test accuracy')\n",
    "    plt.xlabel('Proportion of nodes/filters remaining')\n",
    "    plt.legend(loc = 'lower left')\n",
    "    plt.savefig('Images/test_accuracy_{}.png'.format(name))\n",
    "\n",
    "    if oracle:\n",
    "        # Plot figures for oracle comparison\n",
    "        plt.figure()\n",
    "        plt.gca().invert_xaxis()\n",
    "        plt.xscale('log')\n",
    "        plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "        for masktype in masktypes:\n",
    "            length = len(percentremoved[masktype])//numtrials\n",
    "            mean = []\n",
    "            std = []\n",
    "            for i in range(length):\n",
    "                mean.append(np.mean(oraclecomparison[masktype][i::length]))\n",
    "                std.append(1.96*np.std(oraclecomparison[masktype][i::length])/np.sqrt(numtrials))\n",
    "            plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)\n",
    "        plt.ylabel('Test accuracy')\n",
    "        plt.xlabel('Proportion of nodes/filters remaining')\n",
    "        plt.legend(loc = 'lower left')\n",
    "        plt.savefig('Images/oracle_comparison_{}.png'.format(name))\n",
    "\n",
    "    # Plot figures for early stopping iteration\n",
    "    plt.figure()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xscale('log')\n",
    "    plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "    for masktype in masktypes:\n",
    "        length = len(percentremoved[masktype])//numtrials\n",
    "        mean = []\n",
    "        std = []\n",
    "        for i in range(length):\n",
    "            mean.append(np.mean(early_stopping[masktype][i::length]))\n",
    "            std.append(1.96*np.std(early_stopping[masktype][i::length])/np.sqrt(numtrials))\n",
    "        plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)\n",
    "        plt.ylabel('Early stopping iteration')\n",
    "        plt.xlabel('Proportion of nodes/filters remaining')\n",
    "        plt.legend(loc = 'lower left')\n",
    "        plt.savefig('Images/early_stopping_{}.png'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddMask(mask, model, activationarray, layer, initialize = True):\n",
    "    \"\"\"Function to add mask to current layer of nodes\n",
    "    Inputs:\n",
    "    mask - mask which contains either 0 (node/filter dropped) or 1 (node/filter remaining)\n",
    "    model - Keras model, defined using Functional API\n",
    "    activationarray - list of Keras layers of which we care about their activation values\n",
    "    layer - the current layer number\n",
    "    initialize - Boolean. True if we want to reset all the masks to 1\n",
    "    \n",
    "    Output:\n",
    "    model - Updated Keras model with the mask layer\n",
    "    activationarray - Updated list of layers which the activation values are important\n",
    "    layer - the updated layer number count\n",
    "    \"\"\"\n",
    "    # only initialize if this is the first time\n",
    "    if initialize is True:\n",
    "        mask[layer] = np.ones(model.shape[1:])\n",
    "    model = Multiply()([model, tf.ones_like(model)*mask[layer].reshape(model.shape[1:])])\n",
    "    activationarray.append(model)\n",
    "    \n",
    "    # increase layer count for next iteration\n",
    "    layer = layer+1\n",
    "\n",
    "    return model, activationarray, layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization, Lambda\n",
    "\n",
    "def AddFilterMask(mask, model, activationarray, layer, initialize = True):\n",
    "    \"\"\"Function to add mask to filters in Conv2D\n",
    "    Inputs:\n",
    "    mask - mask which contains either 0 (node/filter dropped) or 1 (node/filter remaining)\n",
    "    model - Keras model, defined using Functional API\n",
    "    activationarray - list of Keras layers of which we care about their activation values\n",
    "    layer - the current layer number\n",
    "    initialize - Boolean. True if we want to reset all the masks to 1\n",
    "    \n",
    "    Output:\n",
    "    model - Updated Keras model with the mask layer\n",
    "    activationarray - Updated list of layers which the activation values are important\n",
    "    layer - the updated layer number count\n",
    "    \"\"\"\n",
    "\n",
    "    model2 = GlobalAveragePooling2D()(model)\n",
    "    \n",
    "    # only initialize if this is the first time\n",
    "    if initialize is True:\n",
    "        mask[layer] = np.ones(model2.shape[1:])\n",
    "    # Multiply the activation with the filters\n",
    "    model2 = Multiply()([model2, tf.ones_like(model2)*mask[layer].reshape(model2.shape[1:])])\n",
    "    activationarray.append(model2)\n",
    "    \n",
    "    # do the multiply for the original filters using broadcasting\n",
    "    model = Multiply()([model, tf.ones_like(model)*mask[layer].reshape(1, 1, model.shape[3])])\n",
    "    \n",
    "    # increase layer count for next iteration\n",
    "    layer = layer+1\n",
    "\n",
    "    return model, activationarray, layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def savefile(cache, name):\n",
    "    \"\"\" Function which saves the cache \"\"\"\n",
    "    with open('Caches/'+name+'.p','wb') as outfile:\n",
    "        pickle.dump(cache, outfile)\n",
    "        \n",
    "def loadfile(name):\n",
    "    \"\"\" Function which loads the cache \"\"\"\n",
    "    with open('Caches/'+name+'.p','rb') as infile:\n",
    "        cache = pickle.load(infile)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Load Cache to Print Graph (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads only one .p file to print the graphs\n",
    "# Enter desired filename below\n",
    "filename = 'cifar10_conv64x2_conv128x2_evaluate'\n",
    "\n",
    "# Load cache\n",
    "cache = loadfile(filename)\n",
    "\n",
    "# print out graphs. Set oracle = True to see oraclecomparison (only valid for oraclemodel)\n",
    "printgraph(cache, filename, numtrials = 15, oracle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the entire Cache folder and prints out all the graphs\n",
    "import os\n",
    "for filename in os.listdir('Caches/'):\n",
    "    if(filename[-1]=='p'):\n",
    "        with open('Caches/'+filename,'rb') as infile:\n",
    "                cache = pickle.load(infile)\n",
    "        modelname = filename[:-2];\n",
    "        printgraph(cache, modelname, numtrials = 15)\n",
    "\n",
    "# this creates the zip file of images imag.zip\n",
    "!zip imag.zip -r Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test/255.0\n",
    "\n",
    "# split into train and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, stratify = y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 394\n",
    "plt.imshow(x_train[index].reshape(28, 28))\n",
    "plt.show()\n",
    "print('Classified as: ' + str(y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.1: Customize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Lambda, Multiply, Flatten, Reshape, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def initializemodel(mask = None):\n",
    "    \"\"\"Initialize model with a certain mask\"\"\"\n",
    "    activationarray = []\n",
    "    layername = {}\n",
    "    # if no mask specified, start with no mask\n",
    "    layer = 0\n",
    "    if mask is None:\n",
    "        mask = {}\n",
    "        initialize = True\n",
    "    else:\n",
    "        initialize = False\n",
    "    \n",
    "    inputs = Input(shape = [28, 28, 1])\n",
    "    \n",
    "    ## Define your model architecture below\n",
    "    ## For every FC layer (dense layer), follow up with an AddMask line to add the node mask\n",
    "    ## For every Conv Layer, follow up with an AddFilterMask line to add the filter mask\n",
    "    \n",
    "    # Model A (FC layers)\n",
    "    model = Flatten()(inputs)\n",
    "    \n",
    "    model = Dense(40, activation = 'relu')(model)\n",
    "    model, activationarray, layer = AddMask(mask, model, activationarray, layer, initialize = initialize)  \n",
    "    model = Dense(40, activation = 'relu')(model)\n",
    "    model, activationarray, layer = AddMask(mask, model, activationarray, layer, initialize = initialize) \n",
    "    \n",
    "    out = Dense(10, activation = 'softmax')(model)\n",
    "    \n",
    "    model = Model(inputs = [inputs], outputs = [out])\n",
    "    activationmodel = Model(inputs = [inputs], outputs = activationarray)\n",
    "    \n",
    "##     Model B (Conv layers)\n",
    "    \n",
    "#     model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(inputs)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize) \n",
    "#     model = MaxPooling2D((2, 2))(model)\n",
    "#     model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = MaxPooling2D((2, 2))(model)    \n",
    "    \n",
    "#     model = Flatten()(model)\n",
    "    \n",
    "#     out = Dense(10, activation = 'softmax')(model)\n",
    "    \n",
    "#     model = Model(inputs = [inputs], outputs = [out])\n",
    "#     activationmodel = Model(inputs = [inputs], outputs = activationarray)\n",
    "    \n",
    "    return mask, model, activationmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.2: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model evaluation to compare all metrics\n",
    "cache = generatemodel(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'], num_epochs = 100, numtrials = 15, percentile = 0.2, verbose = 0, printvalue = True, printmask = False, printactivation = False)\n",
    "\n",
    "## Change your model name accordingly\n",
    "modelname = 'mnist_dense40_dense40_evaluate'\n",
    "\n",
    "## If want to print oraclecomparison graph, set to oracle = True (only for oraclemodel)\n",
    "printgraph(cache, modelname, numtrials = 15, oracle = False)\n",
    "savefile(cache, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.3: Oracle Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison of min, max and random_layer metric with oracle\n",
    "cache = oraclemodel(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'], num_epochs = 100, numtrials = 15, percentile = 0.2, verbose = 0, printvalue = True, printmask = False, printactivation = False)\n",
    "\n",
    "## Change your model name accordingly\n",
    "modelname = 'mnist_dense40_dense40_oraclemodel'\n",
    "\n",
    "## If want to print oraclecomparison graph, set to oracle = True (only for oraclemodel)\n",
    "printgraph(cache, modelname, numtrials = 15, oracle = True)\n",
    "savefile(cache, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.4: Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison of min metric with randominit\n",
    "cache = comparerandom(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'], num_epochs = 100, numtrials = 15, percentile = 0.2, verbose = 0, printvalue = True, printmask = False, printactivation = False)\n",
    "\n",
    "## Change your model name accordingly\n",
    "modelname = 'mnist_dense40_dense40_comparerandom'\n",
    "\n",
    "## If want to print oraclecomparison graph, set to oracle = True (only for oraclemodel)\n",
    "printgraph(cache, modelname, numtrials = 15, oracle = False)\n",
    "savefile(cache, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.5: Compare Percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison of various pruning percentiles on min metric\n",
    "cache = comparepercentmask(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'], num_epochs = 100, numtrials = 15, percentile = 0.2, verbose = 0, printvalue = True, printmask = False, printactivation = False)\n",
    "\n",
    "## Change your model name accordingly\n",
    "modelname = 'mnist_dense40_dense40_comparepercent'\n",
    "\n",
    "## If want to print oraclecomparison graph, set to oracle = True (only for oraclemodel)\n",
    "printgraph(cache, modelname, numtrials = 15, oracle = False)\n",
    "savefile(cache, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cifar = keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "x_train = x_train.reshape(-1, 32, 32, 3)\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test.reshape(-1, 32, 32, 3)\n",
    "x_test = x_test/255.0\n",
    "\n",
    "# split into train and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, stratify = y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 39\n",
    "plt.imshow(x_train[index])\n",
    "plt.show()\n",
    "print('Classified as: ' + str(y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4.1: Customize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Lambda, Multiply, Flatten, Reshape, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def initializemodel(mask = None):\n",
    "    \"\"\"Initialize model with a certain mask\"\"\"\n",
    "    activationarray = []\n",
    "    layername = {}\n",
    "    # if no mask specified, start with no mask\n",
    "    layer = 0\n",
    "    if mask is None:\n",
    "        mask = {}\n",
    "        initialize = True\n",
    "    else:\n",
    "        initialize = False\n",
    "    \n",
    "    inputs = Input(shape = [32, 32, 3])\n",
    "    \n",
    "    ## Define your model architecture below\n",
    "    ## For every FC layer (dense layer), follow up with an AddMask line to add the node mask\n",
    "    ## For every Conv Layer, follow up with an AddFilterMask line to add the filter mask\n",
    "    \n",
    "    # Model C (Conv layers)\n",
    "    model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(inputs)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Flatten()(model)\n",
    "\n",
    "    # Multiply by mask on nodes (Drop nodes)\n",
    "    model = Dense(256, activation = 'relu')(model)\n",
    "    \n",
    "    out = Dense(10, activation = 'softmax')(model)\n",
    "    \n",
    "    model = Model(inputs = [inputs], outputs = [out])\n",
    "    activationmodel = Model(inputs = [inputs], outputs = activationarray)\n",
    "    \n",
    "    return mask, model, activationmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ResNet18\n",
    "\n",
    "# # [64] x 1, 1/2\n",
    "#     model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(inputs)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)  \n",
    "#     shortcut = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "#     # [64, 64] x 2, 1/2\n",
    "#     model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     shortcut = Add()([shortcut, model])\n",
    "    \n",
    "#     model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Add()([shortcut, model])\n",
    "#     shortcut = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "#     # [128, 128] x 2, 1/2\n",
    "#     model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     shortcut = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     shortcut, activationarray, layer = AddFilterMask(mask, shortcut, activationarray, layer, initialize = initialize)\n",
    "#     shortcut = Add()([shortcut, model])\n",
    "    \n",
    "#     model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Add()([shortcut, model])\n",
    "#     shortcut = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "#     # [256, 256] x 2, 1/2\n",
    "#     model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     shortcut = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     shortcut, activationarray, layer = AddFilterMask(mask, shortcut, activationarray, layer, initialize = initialize)\n",
    "#     shortcut = Add()([shortcut, model])\n",
    "    \n",
    "#     model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Add()([shortcut, model])\n",
    "#     shortcut = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "#     # [512, 512] x 2, 1/2\n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     shortcut = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     shortcut, activationarray, layer = AddFilterMask(mask, shortcut, activationarray, layer, initialize = initialize)\n",
    "#     shortcut = Add()([shortcut, model])\n",
    "    \n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Add()([shortcut, model])\n",
    "    \n",
    "#     model = GlobalAveragePooling2D()(model)  \n",
    "\n",
    "#     # Multiply by mask on nodes (Drop nodes)\n",
    "#     out = Dense(10, activation = 'softmax')(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VGG-19\n",
    "\n",
    "#     model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(inputs)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "#     model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "#     model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "#     model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "\n",
    "#     model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "# #     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "#     model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "#     model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "#     model = Flatten()(model)\n",
    "\n",
    "#     # Multiply by mask on nodes (Drop nodes)\n",
    "#     model = Dense(256, activation = 'relu')(model)\n",
    "    \n",
    "#     out = Dense(10, activation = 'softmax')(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4.2: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model evaluation to compare all metrics\n",
    "cache = generatemodel(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'], num_epochs = 100, numtrials = 15, percentile = 0.2, verbose = 0, printvalue = True, printmask = False, printactivation = False)\n",
    "\n",
    "## Change your model name accordingly\n",
    "modelname = 'cifar10_conv64x2_conv128x2_evaluate'\n",
    "\n",
    "## If want to print oraclecomparison graph, set to oracle = True (only for oraclemodel)\n",
    "printgraph(cache, modelname, numtrials = 15, oracle = False)\n",
    "savefile(cache, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4.3: Oracle Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison of min, max and random_layer metric with oracle\n",
    "cache = oraclemodel(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'], num_epochs = 100, numtrials = 15, percentile = 0.2, verbose = 0, printvalue = True, printmask = False, printactivation = False)\n",
    "\n",
    "## Change your model name accordingly\n",
    "modelname = 'cifar10_conv64x2_conv128x2_oraclemodel'\n",
    "\n",
    "## If want to print oraclecomparison graph, set to oracle = True (only for oraclemodel)\n",
    "printgraph(cache, modelname, numtrials = 15, oracle = True)\n",
    "savefile(cache, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4.4: Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison of min metric with randominit\n",
    "cache = comparerandom(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'], num_epochs = 100, numtrials = 15, percentile = 0.2, verbose = 0, printvalue = True, printmask = False, printactivation = False)\n",
    "\n",
    "## Change your model name accordingly\n",
    "modelname = 'cifar10_conv64x2_conv128x2_comparerandom'\n",
    "\n",
    "## If want to print oraclecomparison graph, set to oracle = True (only for oraclemodel)\n",
    "printgraph(cache, modelname, numtrials = 15, oracle = False)\n",
    "savefile(cache, modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4.5: Compare Percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparison of various pruning percentiles on min metric\n",
    "cache = comparepercentmask(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'], num_epochs = 100, numtrials = 15, percentile = 0.2, verbose = 0, printvalue = True, printmask = False, printactivation = False)\n",
    "\n",
    "## Change your model name accordingly\n",
    "modelname = 'cifar10_conv64x2_conv128x2_comparepercent'\n",
    "\n",
    "## If want to print oraclecomparison graph, set to oracle = True (only for oraclemodel)\n",
    "printgraph(cache, modelname, numtrials = 15, oracle = False)\n",
    "savefile(cache, modelname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
