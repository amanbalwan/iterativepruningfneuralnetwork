{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "<b>Dependencies required:</b>\n",
    "- tensorflow2.x\n",
    "- keras (comes from tensorflow.keras)\n",
    "- numpy\n",
    "- copy\n",
    "- sklearn\n",
    "- matplotlib\n",
    "\n",
    "<b>Setup requirements:</b>\n",
    "- Set up a folder named 'Images' (same directory as this Jupyter Notebook) to store the output images from the model\n",
    "- Set up a folder named 'Caches' (same directory as this Jupyter Notebook) to store the caches from the model\n",
    "\n",
    "<b>Section descriptions:</b>\n",
    "- <b>Section 1: Generic Initialization</b>\n",
    "    - Run all the code under Section 1. These are the code to define the main functions required for the experiments. The flattenmask() function has been updated here to compare with Average Percentage of Zeros (APoZ).\n",
    "- <b>Section 2: CIFAR10</b>\n",
    "    - Run the codes here for experiments on the CIFAR10 dataset\n",
    "        - Section 2.1: Customize Model\n",
    "            - Allows you to customize the model used for the experiment.\n",
    "        - Section 2.2: Evaluate Model\n",
    "            - Allows you to run code to evaluate performance of various metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Generic Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenmask(mask):\n",
    "    \"\"\"Returns the nodes of mask flattened\n",
    "    Input:\n",
    "    mask - the mask position, in dictionary form\n",
    "    Output:\n",
    "    maskflatten - the mask position, flattened out in 1D array\n",
    "    \"\"\"\n",
    "    maskflatten = []\n",
    "    for k, v in mask.items():\n",
    "        curmask = v.flatten()\n",
    "        maskflatten = np.hstack([maskflatten, curmask])\n",
    "    return maskflatten\n",
    "\n",
    "def getmask(layers, mask, maskflatten, mask_type = 'min', percentile = 0.2, printactivation = False, dropOne = False):\n",
    "    \"\"\" Updates mask after each training cycle\n",
    "    Inputs:\n",
    "    layers - Predicted node value per layer\n",
    "    mask - current mask\n",
    "    mask_type - type of mask: min, max, random, min_layer, max_layer, random_layer, apoz, apoz_layer\n",
    "    maskflatten - Flattened masked indices per layer (1 for mask, 0 for no mask)\n",
    "    percentile - percentage of nodes remaining to be masked\n",
    "    printactivation - Boolean. Whether to print the activations per layer\n",
    "    dropOne - Boolean. Whether to drop only one node/filter at a time\n",
    "    \n",
    "    Output:\n",
    "    mask - final masks after masking percentile proportion of remaining nodes\n",
    "    \"\"\"\n",
    "    nodevalues = []\n",
    "    layermeans = {}\n",
    "    \n",
    "    # if only drop one, then percentile is 0\n",
    "    if dropOne:\n",
    "        percentile = 0\n",
    "    \n",
    "    # if only one layer\n",
    "    if(len(mask)==1):\n",
    "        # if mask type is apoz, then sum up the number of zero activations\n",
    "        if 'apoz' in mask_type:\n",
    "            layermeans[0] = np.sum(layers==0, axis = 0).ravel()\n",
    "        else:\n",
    "            layermeans[0] = np.mean(np.abs(layers), axis = 0).ravel()\n",
    "        nodevalues = np.hstack([nodevalues, layermeans[0]])\n",
    "        if printactivation:\n",
    "            print('Layer activations:', layermeans[0])\n",
    "        \n",
    "    # if more than one layer\n",
    "    else:\n",
    "        for i in range(len(mask)):\n",
    "            # if mask type is apoz, then sum up the number of zero activations\n",
    "            if 'apoz' in mask_type:\n",
    "                layermeans[i] = np.sum(layers[i]==0, axis = 0).ravel()\n",
    "            else:\n",
    "                layermeans[i] = np.mean(np.abs(layers[i]), axis = 0).ravel()\n",
    "            nodevalues = np.hstack([nodevalues, layermeans[i]])\n",
    "            if printactivation:\n",
    "                print('Layer activations:', layermeans[i])\n",
    "\n",
    "    # remove only those in maskindex\n",
    "    maskflatten = np.ravel(np.where(maskflatten == 1))\n",
    "    \n",
    "    # find out the threshold node/filter value to remove\n",
    "    if len(maskflatten) > 0:\n",
    "        # for max mask\n",
    "        if mask_type == 'max' or 'apoz' in mask_type:\n",
    "            sortedvalues = -np.sort(-nodevalues[maskflatten])\n",
    "            index = int((percentile)*len(sortedvalues))\n",
    "            maxindex = sortedvalues[index]\n",
    "            \n",
    "        # for min or % mask\n",
    "        else:\n",
    "            sortedvalues = np.sort(nodevalues[maskflatten])\n",
    "            index = int(percentile*len(sortedvalues))\n",
    "            maxindex = sortedvalues[index]\n",
    "                           \n",
    "    # Calculate the number of nodes to remove\n",
    "    nummask = 0\n",
    "    \n",
    "    for v in mask.values():\n",
    "        nummask += np.sum(v)\n",
    "    \n",
    "    totalnodes = int((percentile)*nummask)\n",
    "    \n",
    "    if dropOne:\n",
    "        totalnodes = 1\n",
    "\n",
    "    # remove at least one node\n",
    "    if (totalnodes == 0):\n",
    "        totalnodes = 1\n",
    "    \n",
    "    # identify the indices to drop for random mask\n",
    "    if mask_type == 'random':\n",
    "        indices = np.random.permutation(maskflatten)\n",
    "        # take only the first totalnodes number of nodes\n",
    "        indices = indices[:totalnodes]\n",
    "        \n",
    "        dropmaskindex = {}\n",
    "        startindex = 0\n",
    "        # assign nodes/filters to drop for each layer in dropmaskindex\n",
    "        for k, v in mask.items():\n",
    "            nummask += np.sum(v)\n",
    "            dropmaskindex[k] = indices[(indices>=startindex) & (indices < startindex + len(v))] - startindex\n",
    "            startindex += len(v)\n",
    "        \n",
    "    for i, layermean in layermeans.items():\n",
    "\n",
    "        #only if there is something to drop in current mask\n",
    "        if(np.sum(mask[i])>0):\n",
    "            # Have different indices for different masks\n",
    "            if mask_type == 'max' or mask_type == 'apoz':\n",
    "                indices = np.ravel(np.where(layermean>=maxindex))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "                indices = [j for j in indices if j in curindices]\n",
    "            # global random mask or layer random mask\n",
    "            elif mask_type == 'random_layer':\n",
    "                indices = np.ravel(np.where(mask[i].ravel()))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "            elif mask_type == 'random':\n",
    "                indices = dropmaskindex[i]\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "            # layer-wise max mask\n",
    "            elif mask_type == 'max_layer' or mask_type == 'apoz_layer':\n",
    "                sortedvalues = -np.sort(-layermean[mask[i]==1])\n",
    "                index = int((percentile)*len(sortedvalues))\n",
    "                maxindex = sortedvalues[index]\n",
    "                indices = np.ravel(np.where(layermean>=maxindex))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "                indices = [j for j in indices if j in curindices]\n",
    "            # layer-wise min mask\n",
    "            elif mask_type == 'min_layer':\n",
    "                sortedvalues = np.sort(layermean[mask[i]==1])\n",
    "                index = int((percentile)*len(sortedvalues))\n",
    "                maxindex = sortedvalues[index]\n",
    "                indices = np.ravel(np.where(layermean<=maxindex))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "                indices = [j for j in indices if j in curindices]\n",
    "            # if this is min mask or % based mask\n",
    "            else:\n",
    "                indices = np.ravel(np.where(layermean<=maxindex))\n",
    "                curindices = np.ravel(np.where(mask[i].ravel()))\n",
    "                indices = [j for j in indices if j in curindices]\n",
    "                \n",
    "        else:\n",
    "            #default\n",
    "            indices = np.ravel(np.where(mask[i]==1))\n",
    "\n",
    "        # shuffle the indices only if we are not dropping one node/filter\n",
    "        if (dropOne == False):\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        newmask = mask[i].ravel()\n",
    "\n",
    "        # for layer masks, total nodes dropped is by percentile of the layer of each mask\n",
    "        if 'layer' in mask_type:\n",
    "            initialpercent = np.sum(mask[i])*1.0/len(mask[i].ravel())\n",
    "            totalnodes = int(initialpercent*(percentile)*len(mask[i].ravel()))\n",
    "\n",
    "            # remove at least 1 node\n",
    "            if (totalnodes == 0):\n",
    "                totalnodes = 1\n",
    "\n",
    "        if(len(indices)>0):\n",
    "\n",
    "            # remove at most totalnodes number of nodes\n",
    "            if(len(indices)>totalnodes):\n",
    "                indices = indices[:totalnodes]\n",
    "\n",
    "            # remove nodes\n",
    "            newmask[indices] = 0\n",
    "\n",
    "            # updated totalnodes to be removed\n",
    "            totalnodes = totalnodes - len(indices)\n",
    "\n",
    "        # reshape to fit new mask\n",
    "        mask[i] = newmask.reshape(mask[i].shape)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def resetmask(mask):\n",
    "    \"\"\"Resets mask to initial start state of all ones\"\"\"\n",
    "    for k, v in mask.items():\n",
    "        mask[k] = np.ones_like(v)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def comparemask(mask1, mask2):\n",
    "    \"\"\" Compares how similar both masks (mask1, mask2) are and returns a percentage similarity \"\"\"\n",
    "    count = 0\n",
    "    totalcount = 0\n",
    "    for k, v in mask1.items():\n",
    "        count += np.sum(mask1[k] == mask2[k])\n",
    "        totalcount += len(mask1[k].ravel())\n",
    "        \n",
    "    return count/totalcount\n",
    "\n",
    "def percentmask(mask):\n",
    "    \"\"\"Returns the percentage of mask that contains 1s\"\"\"\n",
    "    nummask = 0\n",
    "    totalmask = 0\n",
    "    \n",
    "    for v in mask.values():\n",
    "        nummask += np.sum(v)\n",
    "        totalmask += len(v.ravel())\n",
    "        \n",
    "    return nummask/totalmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def generatemodel(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'],\n",
    "                  callbacks = [EarlyStopping(monitor='val_loss', mode = 'min', verbose=0, patience=5)], \n",
    "                    num_epochs = 100, percentile = 0.2, verbose = 0, numtrials = 15, printvalue = True, printmask = False, printactivation = False):\n",
    "    \"\"\" Function to evaluate the model against various metrics\n",
    "    Inputs:\n",
    "    opt - Keras optimizer\n",
    "    loss - Keras loss\n",
    "    metrics - Keras metrics\n",
    "    callbacks - Keras callbacks\n",
    "    num_epochs - Number of epochs for each training cycle\n",
    "    percentile - Percentile to drop the nodes\n",
    "    verbose - Keras verbose option\n",
    "    numtrials - Number of different experiments to run, each with different random seed\n",
    "    printvalue  - Boolean. Whether to print the accuracies and losses for each pruning percentage\n",
    "    printmask - Boolean. Whether to print the mask values\n",
    "    printactivation - Boolean. Whether to print the node/filter's activation values\n",
    "    \n",
    "    Output:\n",
    "    caches - Cache containing accuracies, losses, early stopping iteration and oracle comparison\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables\n",
    "    percentremoved ={}\n",
    "    train_accuracies = {}\n",
    "    valid_accuracies = {}\n",
    "    test_accuracies = {}\n",
    "    train_losses = {}\n",
    "    valid_losses ={}\n",
    "    test_losses = {}\n",
    "    early_stopping = {}\n",
    "    oraclecomparison = {}\n",
    "    masktypes = ['min', 'min_layer', 'apoz', 'apoz_layer']\n",
    "    \n",
    "    for masktype in masktypes:\n",
    "        percentremoved[masktype] = []\n",
    "        train_accuracies[masktype] = []\n",
    "        valid_accuracies[masktype] = []\n",
    "        test_accuracies[masktype] = []\n",
    "        train_losses[masktype] = []\n",
    "        valid_losses[masktype] = []\n",
    "        test_losses[masktype] = []\n",
    "        early_stopping[masktype] = []\n",
    "        \n",
    "    # do for numtrials number of random seeds\n",
    "    for random_seed in range(numtrials):\n",
    "        print('>>>     Random seed number:', random_seed)\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        tf.random.set_seed(random_seed)    \n",
    "        \n",
    "        # Initialize the model\n",
    "        mask, model, activationmodel = initializemodel()\n",
    "        # model.summary()\n",
    "        model.compile(optimizer = opt, loss = loss, metrics = metrics)\n",
    "        # save original weights\n",
    "        weights_initial = model.get_weights()\n",
    "    \n",
    "    # do for all mask types\n",
    "        for masktype in masktypes:\n",
    "            print('\\n>>> Currently doing', masktype, 'mask <<<')\n",
    "        \n",
    "            mask=resetmask(mask)\n",
    "            percent = percentmask(mask)\n",
    "            \n",
    "            while percent > 0.1:\n",
    "                # Initialize the model with the new mask\n",
    "                tf.keras.backend.clear_session()\n",
    "                del model\n",
    "                gc.collect()\n",
    "                \n",
    "                np.random.seed(random_seed)\n",
    "                tf.random.set_seed(random_seed)  \n",
    "                \n",
    "                _, model, activationmodel = initializemodel(mask)\n",
    "\n",
    "                #Initialize to original weights\n",
    "                model.set_weights(weights_initial)\n",
    "                model.compile(optimizer = opt, loss = loss, metrics = metrics)  \n",
    "\n",
    "                history = model.fit(x_train, y_train, epochs = num_epochs, validation_data = (x_val, y_val), callbacks = callbacks, shuffle = False, verbose = verbose)\n",
    "                results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "                percent = percentmask(mask)\n",
    "                train_accuracy = history.history['accuracy'][-1]\n",
    "                valid_accuracy = history.history['val_accuracy'][-1]\n",
    "                test_accuracy = results[1]\n",
    "                train_loss = history.history['loss'][-1]\n",
    "                valid_loss = history.history['val_loss'][-1]\n",
    "                test_loss = results[0]\n",
    "                early = len(history.history['accuracy'])\n",
    "\n",
    "                # Append the values for accuracy and loss\n",
    "                percentremoved[masktype].append(percent)\n",
    "                train_accuracies[masktype].append(train_accuracy)\n",
    "                valid_accuracies[masktype].append(valid_accuracy)\n",
    "                test_accuracies[masktype].append(test_accuracy)\n",
    "                train_losses[masktype].append(train_loss)\n",
    "                valid_losses[masktype].append(valid_loss)\n",
    "                test_losses[masktype].append(test_loss)\n",
    "                early_stopping[masktype].append(early)\n",
    "\n",
    "                if printvalue:\n",
    "                    print('Percentage remaining', percent, end = ' ')\n",
    "                    print('Layer nodes:', [np.sum(mask[i]) for i in mask.keys()], end = ' ')\n",
    "                    if printmask:\n",
    "                        print('Mask:', mask)\n",
    "                    print('Train Acc:', train_accuracy, end = ' ')\n",
    "                    print('Val Acc:', valid_accuracy, end = ' ')\n",
    "                    print('Test Acc:', test_accuracy)\n",
    "                    print('Train Loss:', train_loss, end = ' ')\n",
    "                    print('Val loss:', valid_loss, end = ' ')\n",
    "                    print('Test Loss:', test_loss)\n",
    "                    print('Early stopping iteration:', early)\n",
    "\n",
    "                # Remove nodes for next iteration based on metric\n",
    "                layers = activationmodel.predict(x_train)\n",
    "                maskflatten = flattenmask(mask)\n",
    "                mask = getmask(layers, mask, maskflatten, mask_type = masktype, percentile = percentile, printactivation = printactivation)\n",
    "                \n",
    "        cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "        printgraph(cache, 'evaluate_resnet18_apoz_resnet_'+str(random_seed), numtrials = random_seed+1)\n",
    "\n",
    "    cache = (percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printgraph(cache, name, numtrials = 15, oracle = False):\n",
    "    \"\"\"Function to print graph\n",
    "    Input: \n",
    "    cache - Cache containing accuracies, losses, early stopping iteration and oracle comparison\n",
    "    name - name of model which is run\n",
    "    numtrials - number of experiments conducted\n",
    "    oracle - Boolean. Whether the oraclecomparison graph is required\n",
    "    \n",
    "    Outputs:\n",
    "    Graphs for training, validation, test accuracy, early stopping iteration, oracle comparison (optional)\"\"\"\n",
    "    \n",
    "    # unpack caches\n",
    "    percentremoved, train_accuracies, valid_accuracies, test_accuracies, train_losses, valid_losses, test_losses, early_stopping, oraclecomparison = cache\n",
    "    # sort masktypes by alphabetical order\n",
    "    masktypes = sorted(percentremoved.keys())\n",
    "\n",
    "    # Set colors\n",
    "    colors = {}\n",
    "    colors['min'] = 'b'\n",
    "    colors['max'] = 'r'\n",
    "    colors['apoz'] = 'r'\n",
    "    colors['random'] ='g'\n",
    "    colors['random_layer'] = 'y'\n",
    "    colors['min_layer'] = 'c'\n",
    "    colors['max_layer'] = 'm'\n",
    "    colors['apoz_layer'] = 'm'\n",
    "    colors['randominit'] = 'y'\n",
    "    colors['oracle'] = 'm'\n",
    "    \n",
    "    # colors for percentage mask\n",
    "    colors['0.1'] = 'b'\n",
    "    colors['0.2'] = 'r'\n",
    "    colors['0.3'] = 'g'\n",
    "    colors['0.4'] = 'y'\n",
    "    colors['0.5'] = 'c'\n",
    "    colors['0.9'] = 'm'\n",
    "    \n",
    "    # format for various masks\n",
    "    fmt = {}\n",
    "    fmt['min'] = '-'\n",
    "    fmt['max'] = '-'\n",
    "    fmt['apoz'] = '-'\n",
    "    fmt['random'] ='--'\n",
    "    fmt['random_layer'] = '--'\n",
    "    fmt['min_layer'] = '-'\n",
    "    fmt['max_layer'] = '-'\n",
    "    fmt['apoz_layer'] = '-'\n",
    "    fmt['randominit'] = '--'\n",
    "    fmt['minfast'] = '-'\n",
    "    fmt['oracle'] = '-'\n",
    "    \n",
    "    fmt['0.1'] = '-'\n",
    "    fmt['0.2'] = '-'\n",
    "    fmt['0.3'] = '-'\n",
    "    fmt['0.4'] = '-'\n",
    "    fmt['0.5'] = '-'\n",
    "    fmt['0.9'] = '-'\n",
    "    \n",
    "    import matplotlib.font_manager\n",
    "    from matplotlib import rc, rcParams\n",
    "    rc('font', family = 'STIXGeneral')\n",
    "    rc('xtick', labelsize=10) \n",
    "    rcParams.update({'figure.autolayout': True})\n",
    "    rcParams.update({'font.size': 14})\n",
    "    \n",
    "    # Plot figures for training accuracy\n",
    "    plt.figure()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xscale('log')\n",
    "    plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "    for masktype in masktypes:     \n",
    "        length = len(percentremoved[masktype])//numtrials\n",
    "        mean = []\n",
    "        std = []\n",
    "        for i in range(length):\n",
    "            mean.append(np.mean(train_accuracies[masktype][i::length]))\n",
    "            std.append(1.96*np.std(train_accuracies[masktype][i::length])/np.sqrt(numtrials))\n",
    "        plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)        \n",
    "    plt.ylabel('Training accuracy')\n",
    "    plt.xlabel('Fraction of filters remaining')\n",
    "    plt.legend(loc = 'lower left')\n",
    "    plt.savefig('Images/training_accuracy_{}.png'.format(name))\n",
    "\n",
    "    # Plot figures for validation accuracy\n",
    "    plt.figure()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xscale('log')\n",
    "    plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "    for masktype in masktypes:\n",
    "        length = len(percentremoved[masktype])//numtrials\n",
    "        mean = []\n",
    "        std = []\n",
    "        for i in range(length):\n",
    "            mean.append(np.mean(valid_accuracies[masktype][i::length]))\n",
    "            std.append(1.96*np.std(valid_accuracies[masktype][i::length])/np.sqrt(numtrials))\n",
    "        plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)\n",
    "    plt.ylabel('Validation accuracy')\n",
    "    plt.xlabel('Fraction of filters remaining')\n",
    "    plt.legend(loc = 'lower left')\n",
    "    plt.savefig('Images/validation_accuracy_{}.png'.format(name))\n",
    "\n",
    "    # Plot figures for test accuracy\n",
    "    plt.figure()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xscale('log')\n",
    "    plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "    for masktype in masktypes:\n",
    "        length = len(percentremoved[masktype])//numtrials\n",
    "        mean = []\n",
    "        std = []\n",
    "        for i in range(length):\n",
    "            mean.append(np.mean(test_accuracies[masktype][i::length]))\n",
    "            std.append(1.96*np.std(test_accuracies[masktype][i::length])/np.sqrt(numtrials))\n",
    "        plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)\n",
    "    plt.ylabel('Test accuracy')\n",
    "    plt.xlabel('Fraction of filters remaining')\n",
    "    plt.legend(loc = 'lower left')\n",
    "    plt.savefig('Images/test_accuracy_{}.png'.format(name))\n",
    "\n",
    "    if oracle:\n",
    "        # Plot figures for oracle comparison\n",
    "        plt.figure()\n",
    "        plt.gca().invert_xaxis()\n",
    "        plt.xscale('log')\n",
    "        plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "        for masktype in masktypes:\n",
    "            length = len(percentremoved[masktype])//numtrials\n",
    "            mean = []\n",
    "            std = []\n",
    "            for i in range(length):\n",
    "                mean.append(np.mean(oraclecomparison[masktype][i::length]))\n",
    "                std.append(1.96*np.std(oraclecomparison[masktype][i::length])/np.sqrt(numtrials))\n",
    "            plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)\n",
    "        plt.ylabel('Test accuracy')\n",
    "        plt.xlabel('Fraction of filters remaining')\n",
    "        plt.legend(loc = 'lower left')\n",
    "        plt.savefig('Images/oracle_comparison_{}.png'.format(name))\n",
    "\n",
    "    # Plot figures for early stopping iteration\n",
    "    plt.figure()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xscale('log')\n",
    "    plt.xticks([0.1,0.2,0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0], ['0.1','0.2','0.3','0.4','0.5', '0.6', '0.7', '0.8', '0.9', '1.0'], rotation = 45)\n",
    "    for masktype in masktypes:\n",
    "        length = len(percentremoved[masktype])//numtrials\n",
    "        mean = []\n",
    "        std = []\n",
    "        for i in range(length):\n",
    "            mean.append(np.mean(early_stopping[masktype][i::length]))\n",
    "            std.append(1.96*np.std(early_stopping[masktype][i::length])/np.sqrt(numtrials))\n",
    "        plt.errorbar(percentremoved[masktype][:length], mean, yerr = std, fmt = fmt[masktype], capsize = 2, alpha = 0.5, color=colors[masktype], label = masktype)\n",
    "        plt.ylabel('Early stopping iteration')\n",
    "        plt.xlabel('Fraction of filters remaining')\n",
    "        plt.legend(loc = 'lower left')\n",
    "        plt.savefig('Images/early_stopping_{}.png'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddMask(mask, model, activationarray, layer, initialize = True):\n",
    "    \"\"\"Function to add mask to current layer of nodes\n",
    "    Inputs:\n",
    "    mask - mask which contains either 0 (node/filter dropped) or 1 (node/filter remaining)\n",
    "    model - Keras model, defined using Functional API\n",
    "    activationarray - list of Keras layers of which we care about their activation values\n",
    "    layer - the current layer number\n",
    "    initialize - Boolean. True if we want to reset all the masks to 1\n",
    "    \n",
    "    Output:\n",
    "    model - Updated Keras model with the mask layer\n",
    "    activationarray - Updated list of layers which the activation values are important\n",
    "    layer - the updated layer number count\n",
    "    \"\"\"\n",
    "    # only initialize if this is the first time\n",
    "    if initialize is True:\n",
    "        mask[layer] = np.ones(model.shape[1:])\n",
    "    model = Multiply()([model, tf.ones_like(model)*mask[layer].reshape(model.shape[1:])])\n",
    "    activationarray.append(model)\n",
    "    \n",
    "    # increase layer count for next iteration\n",
    "    layer = layer+1\n",
    "\n",
    "    return model, activationarray, layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization, Lambda\n",
    "\n",
    "def AddFilterMask(mask, model, activationarray, layer, initialize = True):\n",
    "    \"\"\"Function to add mask to filters in Conv2D\n",
    "    Inputs:\n",
    "    mask - mask which contains either 0 (node/filter dropped) or 1 (node/filter remaining)\n",
    "    model - Keras model, defined using Functional API\n",
    "    activationarray - list of Keras layers of which we care about their activation values\n",
    "    layer - the current layer number\n",
    "    initialize - Boolean. True if we want to reset all the masks to 1\n",
    "    \n",
    "    Output:\n",
    "    model - Updated Keras model with the mask layer\n",
    "    activationarray - Updated list of layers which the activation values are important\n",
    "    layer - the updated layer number count\n",
    "    \"\"\"\n",
    "\n",
    "    model2 = GlobalAveragePooling2D()(model)\n",
    "    \n",
    "    # only initialize if this is the first time\n",
    "    if initialize is True:\n",
    "        mask[layer] = np.ones(model2.shape[1:])\n",
    "    # Multiply the activation with the filters\n",
    "    model2 = Multiply()([model2, tf.ones_like(model2)*mask[layer].reshape(model2.shape[1:])])\n",
    "    activationarray.append(model2)\n",
    "    \n",
    "    # do the multiply for the original filters using broadcasting\n",
    "    model = Multiply()([model, tf.ones_like(model)*mask[layer].reshape(1, 1, model.shape[3])])\n",
    "    \n",
    "    # increase layer count for next iteration\n",
    "    layer = layer+1\n",
    "\n",
    "    return model, activationarray, layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def savefile(cache, name):\n",
    "    \"\"\" Function which saves the cache \"\"\"\n",
    "    with open('Caches/'+name+'.p','wb') as outfile:\n",
    "        pickle.dump(cache, outfile)\n",
    "        \n",
    "def loadfile(name):\n",
    "    \"\"\" Function which loads the cache \"\"\"\n",
    "    with open('Caches/'+name+'.p','rb') as infile:\n",
    "        cache = pickle.load(infile)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cifar = keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "x_train = x_train.reshape(-1, 32, 32, 3)\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test.reshape(-1, 32, 32, 3)\n",
    "x_test = x_test/255.0\n",
    "\n",
    "# split into train and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, stratify = y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified as: [0]\n"
     ]
    }
   ],
   "source": [
    "index = 39\n",
    "plt.imshow(x_train[index])\n",
    "plt.show()\n",
    "print('Classified as: ' + str(y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1: Customize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Add, Dense, Input, Lambda, Multiply, Flatten, Reshape, Conv2D, GlobalAveragePooling2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def initializemodel(mask = None):\n",
    "    \"\"\"Initialize model with a certain mask\"\"\"\n",
    "    activationarray = []\n",
    "    layername = {}\n",
    "    # if no mask specified, start with no mask\n",
    "    layer = 0\n",
    "    if mask is None:\n",
    "        mask = {}\n",
    "        initialize = True\n",
    "    else:\n",
    "        initialize = False\n",
    "    \n",
    "    inputs = Input(shape = [32, 32, 3])\n",
    "    \n",
    "    ## Define your model architecture below\n",
    "    ## For every FC layer (dense layer), follow up with an AddMask line to add the node mask\n",
    "    ## For every Conv Layer, follow up with an AddFilterMask line to add the filter mask\n",
    "    \n",
    "    # ResNet\n",
    "    # [64] x 1, 1/2\n",
    "    model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(inputs)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)  \n",
    "    shortcut = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    # [64, 64] x 2, 1/2\n",
    "    model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    shortcut = Add()([shortcut, model])\n",
    "    \n",
    "    model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Add()([shortcut, model])\n",
    "    shortcut = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    # [128, 128] x 2, 1/2\n",
    "    model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    shortcut = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    shortcut, activationarray, layer = AddFilterMask(mask, shortcut, activationarray, layer, initialize = initialize)\n",
    "    shortcut = Add()([shortcut, model])\n",
    "    \n",
    "    model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Add()([shortcut, model])\n",
    "    shortcut = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    # [256, 256] x 2, 1/2\n",
    "    model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    shortcut = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    shortcut, activationarray, layer = AddFilterMask(mask, shortcut, activationarray, layer, initialize = initialize)\n",
    "    shortcut = Add()([shortcut, model])\n",
    "    \n",
    "    model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Add()([shortcut, model])\n",
    "    shortcut = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    # [512, 512] x 2, 1/2\n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    shortcut = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    shortcut, activationarray, layer = AddFilterMask(mask, shortcut, activationarray, layer, initialize = initialize)\n",
    "    shortcut = Add()([shortcut, model])\n",
    "    \n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(shortcut)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Add()([shortcut, model])\n",
    "    \n",
    "    model = GlobalAveragePooling2D()(model)  \n",
    "\n",
    "    # Multiply by mask on nodes (Drop nodes)\n",
    "    out = Dense(10, activation = 'softmax')(model)\n",
    "    \n",
    "    model = Model(inputs = [inputs], outputs = [out])    \n",
    "    activationmodel = Model(inputs = [inputs], outputs = activationarray)\n",
    "    \n",
    "    return mask, model, activationmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Lambda, Multiply, Flatten, Reshape, Conv2D, AveragePooling2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def initializemodel(mask = None):\n",
    "    \"\"\"Initialize model with a certain mask\"\"\"\n",
    "    activationarray = []\n",
    "    layername = {}\n",
    "    # if no mask specified, start with no mask\n",
    "    layer = 0\n",
    "    if mask is None:\n",
    "        mask = {}\n",
    "        initialize = True\n",
    "    else:\n",
    "        initialize = False\n",
    "    \n",
    "    inputs = Input(shape = [32, 32, 3])\n",
    "    \n",
    "    ## Define your model architecture below\n",
    "    ## For every FC layer (dense layer), follow up with an AddMask line to add the node mask\n",
    "    ## For every Conv Layer, follow up with an AddFilterMask line to add the filter mask\n",
    "    \n",
    "    # Model C (VGG-19)\n",
    "    model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(inputs)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)   \n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(256, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "#     model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = Conv2D(512, (3, 3), padding = 'same', activation = 'relu')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model, activationarray, layer = AddFilterMask(mask, model, activationarray, layer, initialize = initialize)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Flatten()(model)\n",
    "\n",
    "    # Multiply by mask on nodes (Drop nodes)\n",
    "    model = Dense(256, activation = 'relu')(model)\n",
    "    \n",
    "    out = Dense(10, activation = 'softmax')(model)\n",
    "    \n",
    "    model = Model(inputs = [inputs], outputs = [out])    \n",
    "    activationmodel = Model(inputs = [inputs], outputs = activationarray)\n",
    "    \n",
    "    return mask, model, activationmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>     Random seed number: 0\n",
      "\n",
      ">>> Currently doing min mask <<<\n",
      "Percentage remaining 1.0 Layer nodes: [64.0, 64.0, 64.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 256.0, 256.0, 256.0, 256.0, 512.0, 512.0, 512.0, 512.0, 512.0] Train Acc: 0.9203110933303833 Val Acc: 0.7473999857902527 Test Acc: 0.7408999800682068\n",
      "Train Loss: 0.2251536101102829 Val loss: 1.0492509603500366 Test Loss: 1.1018586158752441\n",
      "Early stopping iteration: 11\n",
      "Percentage remaining 0.9 Layer nodes: [33.0, 64.0, 43.0, 62.0, 41.0, 127.0, 105.0, 122.0, 128.0, 79.0, 256.0, 240.0, 252.0, 256.0, 153.0, 510.0, 511.0, 510.0, 507.0, 321.0] Train Acc: 0.9105777740478516 Val Acc: 0.6976000070571899 Test Acc: 0.6958000063896179\n",
      "Train Loss: 0.2514492869377136 Val loss: 1.2065061330795288 Test Loss: 1.2491220235824585\n",
      "Early stopping iteration: 10\n",
      "Percentage remaining 0.81 Layer nodes: [30.0, 62.0, 35.0, 59.0, 31.0, 124.0, 80.0, 115.0, 128.0, 44.0, 256.0, 215.0, 241.0, 256.0, 68.0, 505.0, 507.0, 504.0, 499.0, 129.0] Train Acc: 0.9078222513198853 Val Acc: 0.7146000266075134 Test Acc: 0.703499972820282\n",
      "Train Loss: 0.2584588825702667 Val loss: 1.2166954278945923 Test Loss: 1.2345298528671265\n",
      "Early stopping iteration: 10\n"
     ]
    }
   ],
   "source": [
    "## Model evaluation to compare all metrics\n",
    "cache = generatemodel(opt = SGD(lr = 0.1), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'], num_epochs = 100, numtrials = 15, percentile = 0.1, verbose = 0, printvalue = True, printmask = False, printactivation = False)\n",
    "\n",
    "## Change your model name accordingly\n",
    "modelname = 'cifar10_resnet18_apoz_evaluate'\n",
    "\n",
    "## If want to print oraclecomparison graph, set to oracle = True (only for oraclemodel)\n",
    "printgraph(cache, modelname, numtrials = 15, oracle = False)\n",
    "savefile(cache, modelname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
